{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1\n",
    "### 8/10 perfect solutions required for full score\n",
    "\n",
    "These exercises should be done on a computer using Python. \tPlease submit a Jupyter-notebook, containing both your code and the report in the same file. Provide properly commented code.\n",
    "\n",
    "Some of the tasks involve sparse matrices, to obtain efficient code it is preferable to work with sparse matrices using for example the library `sparse` of  `scipy`. In these exercises you are allowed to work with full matrices if you find it easier, but make sure that the comparisons of the various methods in your implementations, e.g. when comparing running times, are fair. Be explicit about these issues in your report.\n",
    "\n",
    "**You will need an additional Python library for this project:** The library `autograd` will be used to compute the numerical Jacobian. You can install this with `pip install autograd`, `pip3 install autograd` or `conda install autograd` depending on your setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import jacobian\n",
    "import matplotlib.pyplot as plt\n",
    "import decimal as dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Propagation of rounding errors\n",
    "The following exercise illustrates the effects of propagation of rounding errors in a numerical algorithm.\n",
    "\n",
    " \n",
    "We want to make a program to approximate the derivative of a differentiable function $f:\\mathbb{R} \\rightarrow \\mathbb{R}$. We use the following approximation called \"central difference\"\n",
    "\n",
    "$$f'(x)=\\frac{f(x+\\Delta x/2)-f(x-\\Delta x/2)}{\\Delta x}+\\mathcal{O}((\\Delta x)^2),\\qquad f'(x)\\approx \\frac{f(x+\\Delta x/2)-f(x-\\Delta x/2)}{\\Delta x}.$$\n",
    "\n",
    "1. Use a Taylor expansion to prove that the error given by this approximation is indeed $\\mathcal{O}((\\Delta x)^2)$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taylor's Series Theorem:\n",
    "\n",
    "Assume that $f(x)$ has $k+1$ derivatives in an interval containing the points $x_0$ and $x_0+h$. Then $$f(x_0 + h) = f(x_0) + hf'(x_0) + \\frac{h^2}{2}f''(x_0) + ... + \\frac{h^k}{k!}f^{(k)}(x_0) + \\frac{h^k}{(k+1)!}f^{(k+1)}(\\xi)$$ where $\\xi$ is some point between $x_0$ and $x_0+h$.\n",
    "\n",
    "Using Taylor's Seres Theorem, we approximate $f'(x_0)$ ...\n",
    "\n",
    "## Skriv mer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now take $f(x)=\\exp(-x^2)$, and use the formula above to approximate \n",
    "\n",
    "$$\\left.\\frac{d}{dx}\\exp (-x^2)\\right|_{x=\\frac{\\pi}{2}}.$$\n",
    "\n",
    "2. Make a simple Python program to compute the absolute error of the approximation for decreasing values of $\\Delta x$, e.g $\\Delta x=\\frac{1}{2^k}$ for $k=1,2,\\dots , N$, choosing a value of $N$ between $30$ and $40$.\n",
    "Plot the results (values of $\\Delta x$ versus the corresponding absolute error) in a logarithmic scale.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "appdf() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_35132/1740606451.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mxaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myaxis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabsError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexactdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"log\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_35132/1740606451.py\u001b[0m in \u001b[0;36mabsError\u001b[1;34m(f, appdf, exactdf, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0myaxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexactdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mappdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mxaxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mxaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myaxis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: appdf() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def f(x):\n",
    "    return np.exp(-x**2)\n",
    "\n",
    "def appdf(f, x):\n",
    "    return (f(x + ((1 / (2**k)) / 2)) - f(x + ((1 / (2**k)) / 2))) / (1 / (2**k))\n",
    "\n",
    "def exactdf(x):\n",
    "    return -2 * np.exp(-x**2) * x\n",
    "\n",
    "def absError(f, appdf, exactdf, x):\n",
    "    xaxis = []\n",
    "    yaxis = []\n",
    "    f = f(x)\n",
    "    for k in range(1, 40):\n",
    "        yaxis.append(abs(exactdf(f) - appdf(f)))\n",
    "        xaxis.append(1/(2**k))\n",
    "    return xaxis, yaxis\n",
    "\n",
    "axis = np.array(absError(f, appdf, exactdf, math.pi/2))\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.plot(axis[0], axis[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see in your plot that for very small values of $\\Delta x$ the error starts to increase, compromising the convergence of the approximation method. This is due to the propagation of rounding error. The results improve if we can compute our formulae with a higher precision.\n",
    "\n",
    "3. In this exercise you should learn how to use the library `decimal` in Python in order to perform the calculations of the previous experiment with higher precision. \n",
    "Consider the same parameters used in the previous experiment ($\\Delta x=\\frac{1}{2^k}$ for $k=1,2,\\dots , N$ and same $N$ as above), increase the level of precision (look up `getcontext().prec` in the `decimal` library) and produce a plot which does not show the effects of propagation of rounding errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Newton's method\n",
    "\n",
    "In this exercise, we will make use of the `autograd` package. As we have done at the start of this noteobook, when using this package you must `import` Numpy using `autograd.numpy`. We use the `jacobian` function, which approximates the jacobian of functions between Numpy arrays. See the following example.\n",
    "\n",
    "$$ F(x_1, x_2) = (x_1 + x_2, x_1x_2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1.]\n",
      " [1. 3.]]\n"
     ]
    }
   ],
   "source": [
    "def F_0(x):\n",
    "    return np.array([x[0] + x[1], x[1]*x[0]])\n",
    "\n",
    "# Computing the numerical Jacobian\n",
    "DF = jacobian(F_0)\n",
    "# Testing our function\n",
    "x = np.array([3.0, 1.0])\n",
    "print(DF(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. You are given the following function:\n",
    "$$\n",
    "    F(x_1, x_2) = (x_1 + x_1x_2 - 1, x_1^2 + x_2 + 3)\n",
    "$$\n",
    "  - Using the package `autograd` for automatic differentiation to compute Jacobians, create a function `newton` which implements Newton's method for systems of nonlinear equations $F(\\mathbf{x})=0$.\n",
    "  - Apply the method to $F$. These numerical experiments should give evidence that Newton's method converges for these two problems.\n",
    "  - Choose an initial value close enough in $\\infty$-norm to one solution of the system. Plot the values of $\\|\\mathbf{x}^{k+1}-\\mathbf{x}^k\\|_{\\infty}$ and $\\|F(\\mathbf{x}_k)\\|_{\\infty}$ for each iteration  $k=0,1,\\dots, K-1$ where $K$ is the total number of iterations (choose $K$ large enough to make a detailed plot). Use a semi-logarithmic scale on the y-axis (`semilogy` in matplotlib). \n",
    "  - Your answer is your code and a pair of figures with comments in text about what the figures show and what they can tell you about the convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg\n",
    "\n",
    "def newton(F, x, maxIt):\n",
    "    xdiffnorm = []\n",
    "    Fnorm = []\n",
    "    J = jacobian(F)\n",
    "    for i in range(0, maxIt - 1):\n",
    "        z = x - np.dot(np.linalg.inv(J(x)), F(x))\n",
    "        xdiffnorm.append(linalg.norm((z - x), np.inf))\n",
    "        Fnorm.append(linalg.norm(F(x), np.inf))\n",
    "        x = z\n",
    "    return xdiffnorm, Fnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def F(x):\n",
    "    return np.array([x[0] + x[1] * x[0] - 1, x[0]**2 + x[1] + 3])\n",
    "\n",
    "x = np.array([-0.45, -3.21])\n",
    "\n",
    "axis = np.array(newton(F, x, 1000))\n",
    "\n",
    "plt.semilogy(axis[0], axis[1], color = \"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the implemented Newton method and implement a stopping criterion.\n",
    "As stopping criterion, you should use a maximum number of iterations as well as two tolerances $TOL_1$ and $TOL_2$ such that the iteration is stopped whenever $\\|F(\\mathbf{x}^k)\\|_{\\infty}\\le TOL_1$ and $\\|\\mathbf{x}^{k+1}-\\mathbf{x}^k\\|_{\\infty}\\le TOL_2$. \n",
    "Provide numerical evidence that your code works as it should by  printing the values $\\|F(\\mathbf{x}^k)\\|_{\\infty}$ for each iteration , and making a plot of $\\|F(\\mathbf{x}^k)\\|_{\\infty}$, $\\|\\mathbf{x}^{k+1}-\\mathbf{x}^k\\|_{\\infty}$, for all $k$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg\n",
    "\n",
    "def newton(F, x, maxIt, TOL1, TOL2):\n",
    "    xdiffnorm = []\n",
    "    Fnorm = []\n",
    "    J = jacobian(F)\n",
    "    for i in range(0, maxIt - 1):\n",
    "        z = x - np.dot(np.linalg.inv(J(x)), F(x))\n",
    "        xdiffnorm.append(linalg.norm((z - x), np.inf))\n",
    "        Fnorm.append(linalg.norm(F(x), np.inf))\n",
    "        Finf = linalg.norm((z - x), np.inf)\n",
    "        xinf = linalg.norm(F(x), np.inf)\n",
    "        if (Finf <= TOL1) and (xinf <= TOL2):\n",
    "            print(\"Finf <= TOL1 og xinf <= TOL2\")\n",
    "            print(Finf)\n",
    "            break\n",
    "        x = z\n",
    "    return xdiffnorm, Fnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finf <= TOL1 og xinf <= TOL2\n",
      "1.4937100285994376e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def F(x):\n",
    "    return np.array([x[0] + x[1] * x[0] - 1, x[0]**2 + x[1] + 3])\n",
    "\n",
    "x = np.array([-0.45, -3.21])\n",
    "\n",
    "axis = np.array(newton(F, x, 1000, 0.001, 0.001))\n",
    "\n",
    "plt.semilogy(axis[0], axis[1], color = \"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use newtons method to make a function that calculates a n-th root of a matrix $A$. That is, a function that solves $X^n = A$.\n",
    "\n",
    "- Confirm numerically that your implementation is correct.\n",
    "\n",
    "**Hint**. Can you reinterpret the function $F(X) = X^n - A$ as a function between arrays? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F(X, n, A):\n",
    "    return np.array([X**n - A])\n",
    "\n",
    "# print(J(np.array([[3, 3], [3, 3]]), 3, np.array([[3, 3], [3, 3]])))\n",
    "# print(F(np.array([[3, 3], [3, 3]]), 3, np.array([[3, 3], [3, 3]])))\n",
    "\n",
    "def nthroot(F, Tol, A, X, n, maxIt):\n",
    "    x = abs(F(X, n, A))\n",
    "    J = jacobian(F)\n",
    "    for i in range(0, maxIt):\n",
    "        return\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Think of a good way of verifying numerically that the convergence of the Newton iteration is quadratic. \n",
    "- Your answer is the code that does the verification, the evidence it produces and an explanation of why it is evidence for quadratic convergence.\n",
    "\n",
    "**Hint**. You should consider a problem for which you know the solution or alternatively generate a reference solution (i.e. an approximation with *very* high accuracy). Use the definition of quadratic convergence. You can also compute the jacobian exactly (by hand) to eliminate the error from that part of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E\n"
     ]
    }
   ],
   "source": [
    "from sympy import *\n",
    "x = symbols('x')\n",
    "c = limit((1+1/x)**x, x, oo)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Linear systems -Poisson equation-\n",
    "We are going to numerically solve the following equation for $(x,y)\\in [0,1]^2$ with the Dirichlet boundary condition:\n",
    "\t$$\n",
    "\tu_{xx} + u_{yy}= f, \\text{and} \\;\\; u=0 {\\text{ for boundary}} \n",
    "\t$$\n",
    "    where $u_{xx}$ and $u_{yy}$ are the second order partial derivatives of the unknown function $u(x,y)$, and $f(x,y)$ is a given function. We discretize the above problem on the regular equispaced grid: $x_i=\\frac{i}{n+1}$,  and $y_j=\\frac{j}{n+1}$  with $i,j=1,...,n$ ($0$ and $n+1$ correspond to the boundary). \n",
    "    We use the following finite difference approximation\n",
    "    $$u_{xx}(x_i,y_j)+u_{yy}(x_i,y_j)\\approx\\frac{u(x_{i+1},y_j)-2u(x_{i},y_j)+u(x_{i-1},y_j)}{(\\Delta x)^2} +\\frac{u(x_i,y_{j+1})-2u(x_{i},y_{j})+u(x_i,y_{j-1})}{(\\Delta y)^2}.$$\n",
    "Note that we have $\\Delta x=\\Delta y=1/(n+1)$ here. Thus we consider the following linear system to approximate the above problem \n",
    "\t$$\n",
    "\t\\frac{1}{(\\Delta x)^2}A \\mathbf{u}  = \\mathbf{f},\n",
    "\t$$\n",
    "where the left hand side is a finite-difference discretization of $u_{xx} + u_{yy}$, the matrix $A$ is implemented in the code below, and $\\mathbf{f}$ is the discretized vector of function $\\mathbf{f}=(f(x_1,y_1),f(x_2,y_1),...,f(x_n,y_1),f(x_1,y_2),...,f(x_n,y_2),....,f(x_n,y_n))^{\\top}$, as well as $\\mathbf{u}=(u(x_1,y_1),u(x_2,y_1),...,u(x_n,y_1),u(x_1,y_2),...,u(x_n,y_2),....,u(x_n,y_n))^{\\top}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.  1.  0. ...  0.  0.  0.]\n",
      " [ 1. -4.  1. ...  0.  0.  0.]\n",
      " [ 0.  1. -4. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ... -4.  1.  0.]\n",
      " [ 0.  0.  0. ...  1. -4.  1.]\n",
      " [ 0.  0.  0. ...  0.  1. -4.]]\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "from scipy import linalg\n",
    "from scipy.sparse.linalg import eigs\n",
    "\n",
    "# Creating the matrix A.\n",
    "nx, ny = 10, 10\n",
    "m = nx*ny # number of x_i, y_i pairs\n",
    "main_diag = np.ones(m)*-4.0\n",
    "side_diag = np.ones(m-1)\n",
    "side_diag[np.arange(1,m)%nx==0] = 0\n",
    "side_diag2 = np.ones(m-nx)\n",
    "diagonals = [main_diag,side_diag,side_diag,side_diag2,side_diag2]\n",
    "Amatrix = sparse.diags(diagonals, [0, -1, 1,nx,-(nx)])\n",
    "\n",
    "print(Amatrix @ np.identity(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We solve the linear system \n",
    "\t$$\n",
    "\tA \\mathbf{u}  = (\\Delta x)^2 \\mathbf{f},\n",
    "\t$$\n",
    "    in the following.\n",
    "For convenience, we introduce the following notation:\n",
    "\n",
    "- $A_d$ the diagonal part of $A$,\n",
    "- $A_l$ is **minus** the strictly lower-triangular part of $A$,\n",
    "- $A_u$ is **minus** the strictly upper-triangular part of $A$,\n",
    "\n",
    "with this notation, $A = A_d - A_l - A_u$.\n",
    "\n",
    "We will now approximate the solution of this linear system using three different iterative methods of the type \n",
    "\t$$\n",
    "\t\tM \\mathbf{u}^{(k+1)} = N \\mathbf{u}^{(k)}+(\\Delta x)^2\\mathbf{f},\n",
    "\t$$\n",
    "\twhere $A = M - N$ with $|M|\\ne0$. These methods are aslo known as splitting methods and  each choice of $M$ (and $N=M-A$) determines a different method.  We will use the following three iterative methods to calculate approximate solutions to $\\mathbf{u}$:\n",
    "\n",
    "a) Jacobi ($M = A_d$).\n",
    "\n",
    "b) Forward Gauss-Seidel ($M = A_d-A_l$).\n",
    "\n",
    "c) Successive over relaxation ($M = A_d-\\omega A_l$, where you can choose the value of $\\omega$).\n",
    "\n",
    "1. Create a function that implements the above iterative method. This function should take as input the matrix `A` and `M` such that you can use this function for all three methods above, and outputs the solution to the linear system `u`. Use the three methods to find the solution to the linear system with `n=nx=ny=10`, the initial guess $\\mathbf{u}^{(0)}=(1,1,...,1)^\\top\n",
    "$, and the function $f(x,y)=\\exp(-10(x-1/2)^2-10(y-1/2)^2)$. Confirm that what you obtain is indeed a solution numerically. Do not forget to multiply $(\\Delta x)^2$ with $\\mathbf{f}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobi(Amatrix, u, dx, f, maxIt):\n",
    "    M = (-np.diag(np.diag(Amatrix @ np.identity(m))))\n",
    "    N = M - (Amatrix @ np.identity(m))\n",
    "    a = u\n",
    "    for i in range(0, maxIt):\n",
    "        v = np.linalg.inv(M) * N * a + np.linalg.inv(M) * dx * f\n",
    "        a = v\n",
    "    return a\n",
    "\n",
    "def fGS(Amatrix, u, dx, f, MaxIt):\n",
    "    M = (-np.diag(np.diag(Amatrix @ np.identity(m)))) - (-np.tril(Amatrix @ np.identity(m), k=-1))\n",
    "    N = M - (Amatrix @ np.identity(m))\n",
    "    b = u\n",
    "    for j in range(0, maxIt):\n",
    "        v = np.linalg.inv(M) * N * b + np.linalg.inv(M) * dx * f\n",
    "        b = v\n",
    "    return b\n",
    "\n",
    "def SOR(Amatrix, u, dx, f, maxIt, w):\n",
    "    M = (-np.diag(np.diag(Amatrix @ np.identity(m)))) - w * (-np.tril(Amatrix @ np.identity(m), k=-1))\n",
    "    N = M - (Amatrix @ np.identity(m))\n",
    "    c = u\n",
    "    for k in range(0, maxIt):\n",
    "        v = np.linalg.inv(M) * N * c + np.linalg.inv(M) * dx * f\n",
    "        c = v\n",
    "    return c\n",
    "\n",
    "def iterMethod(Amatrix, u, f, maxIt, w):\n",
    "    dx = (1/11)**2\n",
    "    jacobi(Amatrix, u, dx, f, maxIt)\n",
    "    fGS(Amatrix, u, dx, f, maxIt)\n",
    "    SOR(Amatrix, u, dx, f, maxIt, w)\n",
    "    return a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (100,100) (10,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17452/2716125961.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0miterMethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17452/792207787.py\u001b[0m in \u001b[0;36miterMethod\u001b[1;34m(Amatrix, u, f, maxIt, w)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0miterMethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxIt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mdx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mjacobi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxIt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mfGS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxIt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mSOR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxIt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17452/792207787.py\u001b[0m in \u001b[0;36mjacobi\u001b[1;34m(Amatrix, u, dx, f, maxIt)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxIt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (100,100) (10,) "
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "from scipy import linalg\n",
    "from scipy.sparse.linalg import eigs\n",
    "\n",
    "nx, ny = 10, 10\n",
    "m = nx*ny\n",
    "main_diag = np.ones(m)*-4.0\n",
    "side_diag = np.ones(m-1)\n",
    "side_diag[np.arange(1,m)%nx==0] = 0\n",
    "side_diag2 = np.ones(m-nx)\n",
    "diagonals = [main_diag,side_diag,side_diag,side_diag2,side_diag2]\n",
    "Amatrix = sparse.diags(diagonals, [0, -1, 1,nx,-(nx)])\n",
    "\n",
    "def f(x):\n",
    "    return np.array([np.exp(-10 * (x[0] - 1/2)**2 - 10 * (x[1] - 1/2)**2)])\n",
    "\n",
    "# M = (-np.diag(np.diag(Amatrix @ np.identity(m)))) - (-np.tril(Amatrix @ np.identity(m), k=-1))\n",
    "# print(M)\n",
    "u = np.array([1,1,1,1,1,1,1,1,1,1]).T\n",
    "\n",
    "iterMethod(Amatrix, u, f, 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Consider the residual vector $\\mathbf{r}^k:=\\mathbf{f}-A\\mathbf{u}^k$. We wish to compare the speed of convergence for each of the methods above. \n",
    "   - Produce a semi-log plot of the  $2$-norm of the relative residual  $\\frac{\\|\\mathbf{r}^k\\|_2}{\\|\\mathbf{r}^0\\|_2}$ versus the number of iterations. Plot all the methods in the same plot for comparison. \n",
    "   - Try choosing different values of $\\omega$ in the SOR method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
